{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "883048fe"
      },
      "source": [
        "# Análise do Sentimento no Stack Overflow\n",
        "\n",
        "Este notebook explora o sentimento das interações no Stack Overflow, analisando a evolução temporal do sentimento em diferentes tipos de posts e a relação entre o sentimento e características dos usuários.\n",
        "\n",
        "## Configuração Inicial e Carregamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d377d3e"
      },
      "source": [
        "# Dependências já carregadas\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "folder_path = '/content/drive/My Drive/'\n",
        "zip_path = '/content/drive/My Drive/analyzed.zip'\n",
        "json_data = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70a394d4"
      },
      "source": [
        "## Descompactando e Carregando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a5a128f"
      },
      "source": [
        "zip_file_path = '/content/drive/My Drive/analyzed.zip'\n",
        "!cp \"{zip_file_path}\" /content/analyzed.zip\n",
        "!unzip /content/analyzed.zip -d /content/extracted_analyzed\n",
        "!ls /content/extracted_analyzed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10dd39ee"
      },
      "source": [
        "!cp \"/content/drive/My Drive/dump-users.jsonl\" /content/dump_users.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ca2b558"
      },
      "source": [
        "## Carregando Dados de Usuários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d5eec14"
      },
      "source": [
        "import json\n",
        "\n",
        "input_users = '/content/dump_users.jsonl'\n",
        "\n",
        "def get_ids(post, ids):\n",
        "    ids.add(post['owner_user_id'])\n",
        "    if 'answers' in post:\n",
        "        for a in post['answers']:\n",
        "            get_ids(a, ids)\n",
        "    for c in post['comments']:\n",
        "        ids.add(c['user_id'])\n",
        "\n",
        "users = {}\n",
        "with open(input_users, 'r') as f:\n",
        "    users = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33291a32"
      },
      "source": [
        "## Carregando Dados de Posts Analisados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94ba7874"
      },
      "source": [
        "import json\n",
        "\n",
        "json_file_path = '/content/extracted_analyzed/analyzed.jsonl'\n",
        "\n",
        "json_data = []\n",
        "\n",
        "if json_file_path:\n",
        "    print(f\"Opening and reading JSONL file: {json_file_path}\")\n",
        "    try:\n",
        "        with open(json_file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    json_data.append(json.loads(line.strip()))\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON in line: {line}. Error: {e}\")\n",
        "        print(\"JSONL data loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "else:\n",
        "    print(\"No .jsonl file found in the extracted directory.\")\n",
        "\n",
        "print(json_data[:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bcc9e79"
      },
      "source": [
        "## Explorando a Estrutura dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d82dba0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(json_data[0])\n",
        "\n",
        "# Sentimento das respostas\n",
        "print(json_data[0]['body_sentiment'])\n",
        "print(json_data[0]['creation_date'])\n",
        "\n",
        "# Sentimento do comentário\n",
        "\n",
        "print(json_data[0]['comments'][0]['text_sentiment'])\n",
        "print(json_data[0]['comments'][0]['creation_date'])\n",
        "\n",
        "# Sentimento das respostas\n",
        "\n",
        "print(json_data[0]['answers'][0]['body_sentiment'])\n",
        "print(json_data[0]['answers'][0]['creation_date'])\n",
        "\n",
        "# Sentimento dos comentários das respostas\n",
        "\n",
        "print(json_data[0]['answers'][0]['comments'][0]['text_sentiment'])\n",
        "print(json_data[0]['answers'][0]['comments'][0]['creation_date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8e278f3"
      },
      "source": [
        "## Análise Temporal do Sentimento por Tipo de Post\n",
        "\n",
        "Esta seção analisa a evolução do sentimento médio para diferentes tipos de interações (posts, respostas, comentários) ao longo dos anos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83c4cf06"
      },
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Função para extrair o ano\n",
        "from dateutil.parser import parse\n",
        "\n",
        "def extract_year(date_str):\n",
        "    return parse(date_str).year\n",
        "\n",
        "sentiments_by_year = defaultdict(lambda: {'posts': [], 'answers': [], 'post_comments': [], 'answer_comments': []})\n",
        "\n",
        "for item in tqdm(json_data, desc=\"Processing posts\"):\n",
        "    year = extract_year(item['creation_date'])\n",
        "    sentiments_by_year[year]['posts'].append(item['body_sentiment'] - 1)\n",
        "\n",
        "    for c in item.get('comments', []):\n",
        "        cyear = extract_year(c['creation_date'])\n",
        "        sentiments_by_year[cyear]['post_comments'].append(c['text_sentiment'] - 1)\n",
        "\n",
        "    for a in item.get('answers', []):\n",
        "        ayear = extract_year(a['creation_date'])\n",
        "        sentiments_by_year[ayear]['answers'].append(a['body_sentiment'] - 1)\n",
        "\n",
        "        for ac in a.get('comments', []):\n",
        "            acyear = extract_year(ac['creation_date'])\n",
        "            sentiments_by_year[acyear]['answer_comments'].append(ac['text_sentiment'] - 1)\n",
        "\n",
        "# Função para calcular médias\n",
        "def avg(values):\n",
        "    return np.mean(values) if values else 0\n",
        "\n",
        "# Preparação para análise\n",
        "years = sorted(sentiments_by_year.keys())\n",
        "avg_post_sent = [avg(sentiments_by_year[y]['posts']) for y in years]\n",
        "avg_answer_sent = [avg(sentiments_by_year[y]['answers']) for y in years]\n",
        "avg_post_comm_sent = [avg(sentiments_by_year[y]['post_comments']) for y in years]\n",
        "avg_answer_comm_sent = [avg(sentiments_by_year[y]['answer_comments']) for y in years]\n",
        "avg_total_sent = []\n",
        "for y in years:\n",
        "    all_sentiments = (\n",
        "        sentiments_by_year[y]['posts'] +\n",
        "        sentiments_by_year[y]['answers'] +\n",
        "        sentiments_by_year[y]['post_comments'] +\n",
        "        sentiments_by_year[y]['answer_comments']\n",
        "    )\n",
        "    avg_total_sent.append(avg(all_sentiments))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b02fded0"
      },
      "source": [
        "## Visualização da Evolução Temporal do Sentimento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1f9a2d1"
      },
      "source": [
        "# Visualização dos resultados\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(years, avg_post_sent, label='Posts')\n",
        "plt.plot(years, avg_answer_sent, label='Respostas')\n",
        "plt.plot(years, avg_post_comm_sent, label='Comentários em posts')\n",
        "plt.plot(years, avg_answer_comm_sent, label='Comentários em respostas')\n",
        "plt.plot(years, avg_total_sent, label='Total')\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Média de Sentimento')\n",
        "plt.title('Evolução Temporal do Sentimento no Stack Overflow')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('sentimentos_por_ano.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a44d41"
      },
      "source": [
        "## Evolução Temporal do Sentimento com Intervalo de Confiança de 95%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60d6b175"
      },
      "source": [
        "from scipy.stats import sem\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def confidence_interval_95(values):\n",
        "    if len(values) > 1:\n",
        "        return 1.96 * sem(values)\n",
        "    return 0\n",
        "\n",
        "# Preparação para análise\n",
        "years = sorted(sentiments_by_year.keys())\n",
        "\n",
        "def compute_avg_and_ci(key):\n",
        "    avg_list, ci_list = [], []\n",
        "    for y in years:\n",
        "        values = sentiments_by_year[y][key]\n",
        "        avg_list.append(avg(values))\n",
        "        ci_list.append(confidence_interval_95(values))\n",
        "    return avg_list, ci_list\n",
        "\n",
        "avg_post_sent, ci_post = compute_avg_and_ci('posts')\n",
        "avg_answer_sent, ci_answer = compute_avg_and_ci('answers')\n",
        "avg_post_comm_sent, ci_post_comm = compute_avg_and_ci('post_comments')\n",
        "avg_answer_comm_sent, ci_answer_comm = compute_avg_and_ci('answer_comments')\n",
        "\n",
        "avg_total_sent, ci_total = [], []\n",
        "for y in years:\n",
        "    all_sentiments = (\n",
        "        sentiments_by_year[y]['posts'] +\n",
        "        sentiments_by_year[y]['answers'] +\n",
        "        sentiments_by_year[y]['post_comments'] +\n",
        "        sentiments_by_year[y]['answer_comments']\n",
        "    )\n",
        "    avg_total_sent.append(avg(all_sentiments))\n",
        "    ci_total.append(confidence_interval_95(all_sentiments))\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.errorbar(years, avg_post_sent, yerr=ci_post, label='Posts', fmt='-o')\n",
        "plt.errorbar(years, avg_answer_sent, yerr=ci_answer, label='Respostas', fmt='-o')\n",
        "plt.errorbar(years, avg_post_comm_sent, yerr=ci_post_comm, label='Comentários em posts', fmt='-o')\n",
        "plt.errorbar(years, avg_answer_comm_sent, yerr=ci_answer_comm, label='Comentários em respostas', fmt='-o')\n",
        "plt.errorbar(years, avg_total_sent, yerr=ci_total, label='Total', fmt='-o', color='black', linewidth=2)\n",
        "\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Média de Sentimento')\n",
        "plt.title('Evolução Temporal do Sentimento no Stack Overflow (com 95% CI)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('sentimentos_por_ano.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d02c973c"
      },
      "source": [
        "## Análise de Rede e Sentimento por Usuário\n",
        "\n",
        "Esta seção foca na análise do sentimento médio de usuários e a visualização de uma sub-rede com base no sentimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "366f0c87"
      },
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "import networkx as nx\n",
        "from dateutil.parser import parse\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "MIN_YEARS_ACTIVE = 3\n",
        "CURRENT_YEAR = datetime.now().year\n",
        "\n",
        "def extract_year(date_str):\n",
        "    return parse(date_str).year\n",
        "\n",
        "def active_years(start_year):\n",
        "    return CURRENT_YEAR - start_year\n",
        "\n",
        "user_first_activity = {}\n",
        "user_sentiments = defaultdict(list)  # Guarda sentimentos por usuário\n",
        "\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for item in tqdm(json_data, desc=\"Processing posts\"):\n",
        "    post_owner = item.get('owner_user_id')\n",
        "    post_year = extract_year(item['creation_date'])\n",
        "    if post_owner:\n",
        "        user_first_activity.setdefault(post_owner, post_year)\n",
        "\n",
        "    for comment in item.get('comments', []):\n",
        "        commenter = comment.get('user_id')\n",
        "        sentiment = comment.get('sentiment', 0) - 1  # reduz 1 aqui\n",
        "        if commenter:\n",
        "            cyear = extract_year(comment['creation_date'])\n",
        "            user_first_activity.setdefault(commenter, cyear)\n",
        "            if post_owner and commenter != post_owner:\n",
        "                G.add_edge(commenter, post_owner, weight=sentiment, type='comment')\n",
        "                user_sentiments[commenter].append(sentiment)\n",
        "\n",
        "    for answer in item.get('answers', []):\n",
        "        answer_owner = answer.get('owner_user_id')\n",
        "        sentiment = answer.get('sentiment', 0) - 1  # reduz 1 aqui\n",
        "        ayear = extract_year(answer['creation_date'])\n",
        "        if answer_owner:\n",
        "            user_first_activity.setdefault(answer_owner, ayear)\n",
        "            if post_owner and answer_owner != post_owner:\n",
        "                G.add_edge(answer_owner, post_owner, weight=sentiment, type='answer')\n",
        "                user_sentiments[answer_owner].append(sentiment)\n",
        "\n",
        "        for a_comment in answer.get('comments', []):\n",
        "            ac_user = a_comment.get('user_id')\n",
        "            sentiment = a_comment.get('sentiment', 0) - 1  # reduz 1 aqui\n",
        "            if ac_user:\n",
        "                ac_year = extract_year(a_comment['creation_date'])\n",
        "                user_first_activity.setdefault(ac_user, ac_year)\n",
        "                if answer_owner and ac_user != answer_owner:\n",
        "                    G.add_edge(ac_user, answer_owner, weight=sentiment, type='comment')\n",
        "                    user_sentiments[ac_user].append(sentiment)\n",
        "\n",
        "# Filtra usuários com pelo menos N anos de atividade\n",
        "eligible_users = {u for u, y in user_first_activity.items() if active_years(y) >= MIN_YEARS_ACTIVE}\n",
        "G_filtered = G.subgraph(eligible_users).copy()\n",
        "\n",
        "# Calcula sentimento médio de cada usuário\n",
        "for node in G_filtered.nodes():\n",
        "    sentiments = user_sentiments.get(node, [])\n",
        "    avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n",
        "    G_filtered.nodes[node]['avg_sentiment'] = avg_sentiment\n",
        "    user_info = users.get(str(node), {})  # Busca no dicionário users (chave como string)\n",
        "    G_filtered.nodes[node]['reputation'] = user_info.get('reputation', 0)\n",
        "\n",
        "# Exemplo de métricas temporais por ano\n",
        "activity_by_year = defaultdict(lambda: {'nodes': set(), 'edges': 0})\n",
        "\n",
        "for u, v, d in G_filtered.edges(data=True):\n",
        "    year_u = user_first_activity.get(u)\n",
        "    year_v = user_first_activity.get(v)\n",
        "    year = min(year_u, year_v)\n",
        "    activity_by_year[year]['nodes'].update([u, v])\n",
        "    activity_by_year[year]['edges'] += 1\n",
        "\n",
        "print(\"Ano\\tUsuários ativos\\tInterações\")\n",
        "for year in sorted(activity_by_year.keys()):\n",
        "    data = activity_by_year[year]\n",
        "    print(f\"{year}\\t{len(data['nodes'])}\\t\\t{data['edges']}\")\n",
        "\n",
        "# nx.write_graphml(G_filtered, \"rede_usuarios_filtrada.graphml\")\n",
        "\n",
        "top_nodes = sorted(G_filtered.degree, key=lambda x: x[1], reverse=True)[:1000]\n",
        "top_node_ids = set(n for n, _ in top_nodes)\n",
        "\n",
        "# Subgrafo com os 1000 principais nós\n",
        "G_top = G_filtered.subgraph(top_node_ids).copy()\n",
        "\n",
        "pos = nx.spring_layout(G_top, seed=42)\n",
        "sentiments = [G_top.nodes[n]['avg_sentiment'] for n in G_top.nodes()]\n",
        "nx.draw_networkx_nodes(G_top, pos, node_size=80, node_color=sentiments, cmap=plt.cm.coolwarm)\n",
        "nx.draw_networkx_edges(G_top, pos, alpha=0.3)\n",
        "plt.title(\"Top 1000 Usuários - Cor por Sentimento Médio\")\n",
        "plt.colorbar(plt.cm.ScalarMappable(cmap=plt.cm.coolwarm), label=\"Sentimento Médio\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8af4d6a"
      },
      "source": [
        "## Visualização da Rede de Usuários por Sentimento e Participação\n",
        "\n",
        "Este gráfico exibe a rede dos 1000 usuários mais ativos, colorindo os nós pelo sentimento médio e dimensionando-os pela quantidade de interações iniciadas. As arestas são coloridas pelo sentimento da interação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f02ba80"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Seleciona os 1000 nós com maior grau (in + out)\n",
        "top_nodes = sorted(G_filtered.degree, key=lambda x: x[1], reverse=True)[:1000]\n",
        "top_node_ids = set(n for n, _ in top_nodes)\n",
        "G_top = G_filtered.subgraph(top_node_ids).copy()\n",
        "\n",
        "# Layout da rede\n",
        "pos = nx.spring_layout(G_top, seed=150, k=1.2, scale=10.0)\n",
        "\n",
        "# Cor dos nós baseada no sentimento médio\n",
        "sentiments = [G_top.nodes[n]['avg_sentiment'] for n in G_top.nodes()]\n",
        "cmap = plt.cm.coolwarm\n",
        "norm = mcolors.Normalize(vmin=-1, vmax=1)\n",
        "node_colors = [cmap(norm(s)) for s in sentiments]\n",
        "\n",
        "# Tamanho dos nós proporcional à quantidade de interações iniciadas (out-degree)\n",
        "node_sizes = [10 + 30 * G_top.out_degree(n) for n in G_top.nodes()]\n",
        "\n",
        "# Cores das arestas com base no sentimento da interação\n",
        "edge_colors = []\n",
        "for u, v in G_top.edges():\n",
        "    sentiment = G_top[u][v].get('weight', 0)\n",
        "    if sentiment == -1:\n",
        "        edge_colors.append('red')\n",
        "    elif sentiment == 0:\n",
        "        edge_colors.append('gray')\n",
        "    elif sentiment == 1:\n",
        "        edge_colors.append('green')\n",
        "    else:\n",
        "        edge_colors.append('black')\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "nx.draw_networkx_nodes(G_top, pos, node_size=node_sizes, node_color=node_colors)\n",
        "nx.draw_networkx_edges(G_top, pos, edge_color=edge_colors, alpha=0.4)\n",
        "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "sm.set_array([])\n",
        "plt.colorbar(sm, label=\"Sentimento Médio\")\n",
        "plt.title(\"Top 1000 Usuários - Cor por Sentimento Médio, Tamanho por Participação\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87297f7f"
      },
      "source": [
        "## Análise do Sentimento por Grupos de Usuários\n",
        "\n",
        "Esta seção analisa o sentimento médio de usuários agrupados por percentis de participação (quantidade de posts)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45fd45ca"
      },
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "MIN_YEARS_ACTIVE = 3\n",
        "CURRENT_YEAR = datetime.now().year\n",
        "\n",
        "def extract_year(date_str):\n",
        "    return parse(date_str).year\n",
        "\n",
        "def active_years(start_year):\n",
        "    return CURRENT_YEAR - start_year\n",
        "\n",
        "user_first_activity = {}\n",
        "user_sentiments = defaultdict(list)\n",
        "user_participation = defaultdict(int)\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for item in tqdm(json_data, desc=\"Processing posts\"):\n",
        "    post_owner = item.get('owner_user_id')\n",
        "    post_year = extract_year(item['creation_date'])\n",
        "    if post_owner:\n",
        "        user_first_activity.setdefault(post_owner, post_year)\n",
        "        user_participation[post_owner] += 1\n",
        "\n",
        "    for comment in item.get('comments', []):\n",
        "        commenter = comment.get('user_id')\n",
        "        sentiment = comment.get('text_sentiment', 0) - 1\n",
        "        if commenter:\n",
        "            cyear = extract_year(comment['creation_date'])\n",
        "            user_first_activity.setdefault(commenter, cyear)\n",
        "            user_participation[commenter] += 1\n",
        "            if post_owner and commenter != post_owner:\n",
        "                G.add_edge(commenter, post_owner, weight=sentiment, type='comment')\n",
        "                user_sentiments[commenter].append(sentiment)\n",
        "\n",
        "    for answer in item.get('answers', []):\n",
        "        answer_owner = answer.get('owner_user_id')\n",
        "        sentiment = answer.get('body_sentiment', 0) - 1\n",
        "        ayear = extract_year(answer['creation_date'])\n",
        "        if answer_owner:\n",
        "            user_first_activity.setdefault(answer_owner, ayear)\n",
        "            user_participation[answer_owner] += 1\n",
        "            if post_owner and answer_owner != post_owner:\n",
        "                G.add_edge(answer_owner, post_owner, weight=sentiment, type='answer')\n",
        "                user_sentiments[answer_owner].append(sentiment)\n",
        "\n",
        "        for a_comment in answer.get('comments', []):\n",
        "            ac_user = a_comment.get('user_id')\n",
        "            sentiment = a_comment.get('text_sentiment', 0) - 1\n",
        "            if ac_user:\n",
        "                ac_year = extract_year(a_comment['creation_date'])\n",
        "                user_first_activity.setdefault(ac_user, ac_year)\n",
        "                user_participation[ac_user] += 1\n",
        "                if answer_owner and ac_user != answer_owner:\n",
        "                    G.add_edge(ac_user, answer_owner, weight=sentiment, type='comment')\n",
        "                    user_sentiments[ac_user].append(sentiment)\n",
        "\n",
        "eligible_users = {u for u, y in user_first_activity.items() if active_years(y) >= MIN_YEARS_ACTIVE}\n",
        "G_filtered = G.subgraph(eligible_users).copy()\n",
        "\n",
        "for node in G_filtered.nodes():\n",
        "    sentiments = user_sentiments.get(node, [])\n",
        "    avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n",
        "    G_filtered.nodes[node]['avg_sentiment'] = avg_sentiment\n",
        "\n",
        "# Lista com dados dos usuários\n",
        "user_data = []\n",
        "for n in G_filtered.nodes():\n",
        "    user_data.append({\n",
        "        'user_id': n,\n",
        "        'posts': user_participation[n],\n",
        "        'avg_sentiment': G_filtered.nodes[n]['avg_sentiment']\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(user_data)\n",
        "df = df.sort_values(by='posts', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Percentiles\n",
        "percentiles = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 1.00]\n",
        "\n",
        "results = []\n",
        "total_users = len(df)\n",
        "for p in percentiles:\n",
        "    cutoff = max(1, int(total_users * p))\n",
        "    subset = df.iloc[:cutoff]\n",
        "    mean_sentiment = subset['avg_sentiment'].mean()\n",
        "    results.append({\n",
        "        'Faixa': f'Top {int(p * 100)}%',\n",
        "        'Usuários': cutoff,\n",
        "        'Sentimento Médio': round(mean_sentiment, 3)\n",
        "    })\n",
        "\n",
        "tabela_resultados = pd.DataFrame(results)\n",
        "print(tabela_resultados.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d297175a"
      },
      "source": [
        "## Tabela de Sentimento Médio por Percentil de Usuários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfb16048"
      },
      "source": [
        "percentiles = [0.0001, 0.001, 0.01, 0.1, 0.10, 0.25, 1.00]\n",
        "\n",
        "results = []\n",
        "total_users = len(df)\n",
        "for p in percentiles:\n",
        "    cutoff = max(1, int(total_users * p))\n",
        "    subset = df.iloc[:cutoff]\n",
        "    mean_sentiment = subset['avg_sentiment'].mean()\n",
        "    results.append({\n",
        "        'Faixa': f'Top {(p * 100):.2f}%',\n",
        "        'Usuários': cutoff,\n",
        "        'Sentimento Médio': round(mean_sentiment, 3)\n",
        "    })\n",
        "\n",
        "tabela_resultados = pd.DataFrame(results)\n",
        "print(tabela_resultados.to_string(index=False))\n",
        "print(tabela_resultados.to_latex(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5e66772"
      },
      "source": [
        "## Visualização do Sentimento por Percentil de Usuários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b71feb7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "percentiles = [0.0001, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1.00]\n",
        "results = []\n",
        "\n",
        "total_users = len(df)\n",
        "for p in percentiles:\n",
        "    cutoff = max(1, int(total_users * p))\n",
        "    subset = df.iloc[:cutoff]\n",
        "    mean_sentiment = subset['avg_sentiment'].mean()\n",
        "    results.append({\n",
        "        'percentile': p,\n",
        "        'cutoff': cutoff,\n",
        "        'mean_sentiment': mean_sentiment\n",
        "    })\n",
        "\n",
        "result_df = pd.DataFrame(results)\n",
        "\n",
        "result_df = result_df[result_df['percentile'] >= 0.01]\n",
        "percentis = [0.01, 0.2, 0.4, 0.6, 0.8, 1]\n",
        "# Plot 1: Sentimento suavizado por percentil (Top 1%)\n",
        "top_1_cutoff = max(1, int(total_users * 0.01))\n",
        "top_1_df = df.iloc[:top_1_cutoff].copy()\n",
        "top_1_df['rank'] = np.arange(1, len(top_1_df) + 1)\n",
        "top_1_df['percentile'] = top_1_df['rank'] / top_1_cutoff\n",
        "top_1_df['smoothed_sentiment'] = top_1_df['avg_sentiment'].rolling(window=200, center=True).mean()\n",
        "\n",
        "sns.lineplot(data=top_1_df, x='percentile', y='smoothed_sentiment')\n",
        "plt.title('Sentimento dos Usuários por Percentil (Top 1%)')\n",
        "plt.xlabel('Percentil (Top 1%)')\n",
        "plt.ylabel('Sentimento Médio')\n",
        "plt.xticks(result_df['percentile'], [f'{p:.2f}%' for p in percentis])\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Sentimento médio por percentil (Top %)\n",
        "sns.lineplot(data=result_df, x='percentile', y='mean_sentiment', marker='o')\n",
        "plt.title('Sentimento Médio Dos Usuários por Percentil')\n",
        "plt.xlabel('Percentil')\n",
        "plt.ylabel('Sentimento Médio')\n",
        "plt.xticks(result_df['percentile'], [f'{p*100:.0f}%' for p in result_df['percentile']])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6078803"
      },
      "source": [
        "## Análise Temporal do Sentimento para o Top 1% de Usuários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c6b2756"
      },
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "MIN_YEARS_ACTIVE = 3\n",
        "CURRENT_YEAR = datetime.now().year\n",
        "\n",
        "def extract_year(date_str):\n",
        "    return parse(date_str).year\n",
        "\n",
        "def active_years(start_year):\n",
        "    return CURRENT_YEAR - start_year\n",
        "\n",
        "user_first_activity = {}\n",
        "user_sentiments_by_year = defaultdict(lambda: defaultdict(list))\n",
        "user_posts_by_year = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "G = nx.DiGraph()\n",
        "\n",
        "for item in tqdm(json_data, desc=\"Processing posts\"):\n",
        "    post_owner = item.get('owner_user_id')\n",
        "    post_year = extract_year(item['creation_date'])\n",
        "    if post_owner:\n",
        "        user_first_activity.setdefault(post_owner, post_year)\n",
        "        user_posts_by_year[post_year][post_owner] += 1\n",
        "\n",
        "    for comment in item.get('comments', []):\n",
        "        commenter = comment.get('user_id')\n",
        "        sentiment = comment.get('text_sentiment', 0) - 1\n",
        "        if commenter:\n",
        "            cyear = extract_year(comment['creation_date'])\n",
        "            user_first_activity.setdefault(commenter, cyear)\n",
        "            user_posts_by_year[cyear][commenter] += 1\n",
        "            user_sentiments_by_year[cyear][commenter].append(sentiment)\n",
        "            if post_owner and commenter != post_owner:\n",
        "                G.add_edge(commenter, post_owner, weight=sentiment, type='comment')\n",
        "\n",
        "    for answer in item.get('answers', []):\n",
        "        answer_owner = answer.get('owner_user_id')\n",
        "        sentiment = answer.get('body_sentiment', 0) - 1\n",
        "        ayear = extract_year(answer['creation_date'])\n",
        "        if answer_owner:\n",
        "            user_first_activity.setdefault(answer_owner, ayear)\n",
        "            user_posts_by_year[ayear][answer_owner] += 1\n",
        "            user_sentiments_by_year[ayear][answer_owner].append(sentiment)\n",
        "            if post_owner and answer_owner != post_owner:\n",
        "                G.add_edge(answer_owner, post_owner, weight=sentiment, type='answer')\n",
        "\n",
        "        for a_comment in answer.get('comments', []):\n",
        "            ac_user = a_comment.get('user_id')\n",
        "            sentiment = a_comment.get('text_sentiment', 0) - 1\n",
        "            if ac_user:\n",
        "                ac_year = extract_year(a_comment['creation_date'])\n",
        "                user_first_activity.setdefault(ac_user, ac_year)\n",
        "                user_posts_by_year[ac_year][ac_user] += 1\n",
        "                user_sentiments_by_year[ac_year][ac_user].append(sentiment)\n",
        "                if answer_owner and ac_user != answer_owner:\n",
        "                    G.add_edge(ac_user, answer_owner, weight=sentiment, type='comment')\n",
        "\n",
        "# Análise por ano\n",
        "yearly_sentiment = []\n",
        "\n",
        "for year in sorted(user_posts_by_year.keys()):\n",
        "    posts = user_posts_by_year[year]\n",
        "    sentiments = user_sentiments_by_year[year]\n",
        "\n",
        "    eligible_users = {\n",
        "        u for u in posts\n",
        "        if active_years(user_first_activity.get(u, year)) >= MIN_YEARS_ACTIVE and sentiments[u]\n",
        "    }\n",
        "\n",
        "    user_data = [{\n",
        "        'user_id': u,\n",
        "        'posts': posts[u],\n",
        "        'avg_sentiment': sum(sentiments[u]) / len(sentiments[u])\n",
        "    } for u in eligible_users]\n",
        "\n",
        "    if not user_data:\n",
        "        continue\n",
        "\n",
        "    df_year = pd.DataFrame(user_data)\n",
        "    df_year = df_year.sort_values(by='posts', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    cutoff = max(1, int(len(df_year) * 0.01))\n",
        "    top_users = df_year.iloc[:cutoff]\n",
        "    mean_sentiment = top_users['avg_sentiment'].mean()\n",
        "\n",
        "    yearly_sentiment.append({\n",
        "        'year': year,\n",
        "        'mean_sentiment': mean_sentiment,\n",
        "        'n_users': cutoff\n",
        "    })\n",
        "\n",
        "# Plot\n",
        "df_result = pd.DataFrame(yearly_sentiment)\n",
        "df_result = df_result[df_result['year'] <= 2022]\n",
        "plt.plot(df_result['year'], df_result['mean_sentiment'], marker='o')\n",
        "plt.title('Sentimento Médio dos Top 1% por Ano')\n",
        "plt.xlabel('Ano')\n",
        "plt.ylabel('Sentimento Médio')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9939977"
      },
      "source": [
        "## Análise de Sentimento por Atributos de Usuário\n",
        "\n",
        "Esta seção explora a relação entre o sentimento médio dos usuários e seus atributos, como reputação, visualizações, upvotes e downvotes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "638db9eb"
      },
      "source": [
        "users['6069']\n",
        " #[''].get('location', 'Unknown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa8238c4"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from dateutil.parser import parse\n",
        "from collections import defaultdict\n",
        "\n",
        "# Funções auxiliares\n",
        "def extract_year(date_str):\n",
        "    return parse(date_str).year\n",
        "\n",
        "def extract_country(location):\n",
        "    if location and ',' in location:\n",
        "        return location.split(',')[-1].strip()\n",
        "    return 'Unknown'\n",
        "\n",
        "def get_bucket(value, bins):\n",
        "    for b in bins:\n",
        "        if value <= b:\n",
        "            return f\"<= {b}\"\n",
        "    return f\"> {bins[-1]}\"\n",
        "\n",
        "# Bins para agrupamento\n",
        "reputations, views, upvotes, downvotes = [], [], [], []\n",
        "\n",
        "for uid in eligible_users:\n",
        "    if uid in users:\n",
        "        user = users[uid]\n",
        "        reputations.append(user.get('reputation', 0))\n",
        "        views.append(user.get('views', 0))\n",
        "        upvotes.append(user.get('up_votes', 0))\n",
        "        downvotes.append(user.get('down_votes', 0))\n",
        "\n",
        "# 2. Calcula os bins com percentis (5 faixas)\n",
        "def compute_bins(values, q=[0.1, 0.25, 0.5, 0.75]):\n",
        "    return sorted(set(np.percentile(values, [v * 100 for v in q]).astype(int)))\n",
        "\n",
        "reputation_bins = compute_bins(reputations)\n",
        "views_bins = compute_bins(views)\n",
        "upvote_bins = compute_bins(upvotes)\n",
        "downvote_bins = compute_bins(downvotes)\n",
        "\n",
        "# 1. Conta interações por usuário\n",
        "user_interaction_counts = defaultdict(int)\n",
        "\n",
        "for item in json_data:\n",
        "    uid = str(item.get('owner_user_id'))\n",
        "    if uid: user_interaction_counts[uid] += 1\n",
        "\n",
        "    for c in item.get('comments', []):\n",
        "        cid = str(c.get('user_id'))\n",
        "        if cid: user_interaction_counts[cid] += 1\n",
        "\n",
        "    for ans in item.get('answers', []):\n",
        "        aid = str(ans.get('owner_user_id'))\n",
        "        if aid: user_interaction_counts[aid] += 1\n",
        "        for ac in ans.get('comments', []):\n",
        "            acid = str(ac.get('user_id'))\n",
        "            if acid: user_interaction_counts[acid] += 1\n",
        "\n",
        "# 2. Seleciona usuários com ≥ 50 interações\n",
        "eligible_users = {uid for uid, count in user_interaction_counts.items() if count >= 10}\n",
        "\n",
        "# 3. Monta dataset\n",
        "records = []\n",
        "\n",
        "for item in tqdm(json_data, desc=\"Processando dados\"):\n",
        "    year = extract_year(item['creation_date'])\n",
        "    sentiment = item['body_sentiment'] - 1\n",
        "    uid = str(item.get('owner_user_id'))\n",
        "\n",
        "    if uid in eligible_users and uid in users:\n",
        "        user = users[uid]\n",
        "        records.append({\n",
        "            'year': year,\n",
        "            'sentiment': sentiment,\n",
        "            'reputation_bin': get_bucket(user.get('reputation', 0), reputation_bins),\n",
        "            'views_bin': get_bucket(user.get('views', 0), views_bins),\n",
        "            'upvotes_bin': get_bucket(user.get('up_votes', 0), upvote_bins),\n",
        "            'downvotes_bin': get_bucket(user.get('down_votes', 0), downvote_bins),\n",
        "        })\n",
        "\n",
        "    for c in item.get('comments', []):\n",
        "        cid = str(c.get('user_id'))\n",
        "        if cid in eligible_users and cid in users:\n",
        "            user = users[cid]\n",
        "            records.append({\n",
        "                'year': extract_year(c['creation_date']),\n",
        "                'sentiment': c['text_sentiment'] - 1,\n",
        "                'reputation_bin': get_bucket(user.get('reputation', 0), reputation_bins),\n",
        "                'views_bin': get_bucket(user.get('views', 0), views_bins),\n",
        "                'upvotes_bin': get_bucket(user.get('up_votes', 0), upvote_bins),\n",
        "                'downvotes_bin': get_bucket(user.get('down_votes', 0), downvote_bins),\n",
        "            })\n",
        "\n",
        "    for ans in item.get('answers', []):\n",
        "        aid = str(ans.get('owner_user_id'))\n",
        "        if aid in eligible_users and aid in users:\n",
        "            user = users[aid]\n",
        "            records.append({\n",
        "                'year': extract_year(ans['creation_date']),\n",
        "                'sentiment': ans['body_sentiment'] - 1,\n",
        "                'reputation_bin': get_bucket(user.get('reputation', 0), reputation_bins),\n",
        "                'views_bin': get_bucket(user.get('views', 0), views_bins),\n",
        "                'upvotes_bin': get_bucket(user.get('up_votes', 0), upvote_bins),\n",
        "                'downvotes_bin': get_bucket(user.get('down_votes', 0), downvote_bins),\n",
        "            })\n",
        "\n",
        "        for ac in ans.get('comments', []):\n",
        "            acid = str(ac.get('user_id'))\n",
        "            if acid in eligible_users and acid in users:\n",
        "                user = users[acid]\n",
        "                records.append({\n",
        "                    'year': extract_year(ac['creation_date']),\n",
        "                    'sentiment': ac['text_sentiment'] - 1,\n",
        "                    'reputation_bin': get_bucket(user.get('reputation', 0), reputation_bins),\n",
        "                    'views_bin': get_bucket(user.get('views', 0), views_bins),\n",
        "                    'upvotes_bin': get_bucket(user.get('up_votes', 0), upvote_bins),\n",
        "                    'downvotes_bin': get_bucket(user.get('down_votes', 0), downvote_bins),\n",
        "                })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af2f7e9e"
      },
      "source": [
        "## Visualização do Sentimento por Atributos de Usuário ao Longo do Tempo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bac969f2"
      },
      "source": [
        "# 4. Cria DataFrame\n",
        "df = pd.DataFrame(records)\n",
        "df = df[df['year'] <= 2022]\n",
        "df = df[df['views_bin'] != '> 5000']\n",
        "df = df[df['views_bin'] != '<= 10']\n",
        "\n",
        "# 5. Função para plotar\n",
        "def plot_grouped_sentiment(df, group_col, title):\n",
        "    grouped = df.groupby([group_col, 'year'])['sentiment'].mean().reset_index()\n",
        "    pivot = grouped.pivot(index='year', columns=group_col, values='sentiment')\n",
        "\n",
        "    pivot.plot(figsize=(10, 6), marker='o')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Ano\")\n",
        "    plt.ylabel(\"Sentimento Médio\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(title=group_col, fontsize='small')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 6. Gera gráficos\n",
        "plot_grouped_sentiment(df, 'reputation_bin', \"Sentimento por Reputação (Faixas) ao Longo do Tempo\")\n",
        "plot_grouped_sentiment(df, 'views_bin', \"Sentimento por Visualizações ao Longo do Tempo\")\n",
        "plot_grouped_sentiment(df, 'upvotes_bin', \"Sentimento por Upvotes ao Longo do Tempo\")\n",
        "plot_grouped_sentiment(df, 'downvotes_bin', \"Sentimento por Downvotes ao Longo do Tempo\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}